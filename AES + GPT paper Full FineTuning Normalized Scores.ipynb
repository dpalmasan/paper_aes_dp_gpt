{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f104690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import syllables\n",
    "from collections import defaultdict\n",
    "from pqdm.processes import pqdm\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPEN_AI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ccb28",
   "metadata": {},
   "source": [
    "# Define QWK Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782592ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    quadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "\n",
    "def linear_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Calculates the linear weighted kappa\n",
    "    linear_weighted_kappa calculates the linear weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "\n",
    "    linear_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "\n",
    "    linear_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = abs(i - j) / float(num_ratings - 1)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "\n",
    "def kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Calculates the kappa\n",
    "    kappa calculates the kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "\n",
    "    kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "\n",
    "    kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            if i == j:\n",
    "                d = 0.0\n",
    "            else:\n",
    "                d = 1.0\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "\n",
    "def mean_quadratic_weighted_kappa(kappas, weights=None):\n",
    "    \"\"\"\n",
    "    Calculates the mean of the quadratic\n",
    "    weighted kappas after applying Fisher's r-to-z transform, which is\n",
    "    approximately a variance-stabilizing transformation.  This\n",
    "    transformation is undefined if one of the kappas is 1.0, so all kappa\n",
    "    values are capped in the range (-0.999, 0.999).  The reverse\n",
    "    transformation is then applied before returning the result.\n",
    "\n",
    "    mean_quadratic_weighted_kappa(kappas), where kappas is a vector of\n",
    "    kappa values\n",
    "\n",
    "    mean_quadratic_weighted_kappa(kappas, weights), where weights is a vector\n",
    "    of weights that is the same size as kappas.  Weights are applied in the\n",
    "    z-space\n",
    "    \"\"\"\n",
    "    kappas = np.array(kappas, dtype=float)\n",
    "    if weights is None:\n",
    "        weights = np.ones(np.shape(kappas))\n",
    "    else:\n",
    "        weights = weights / np.mean(weights)\n",
    "\n",
    "    # ensure that kappas are in the range [-.999, .999]\n",
    "    kappas = np.array([min(x, .999) for x in kappas])\n",
    "    kappas = np.array([max(x, -.999) for x in kappas])\n",
    "\n",
    "    z = 0.5 * np.log((1 + kappas) / (1 - kappas)) * weights\n",
    "    z = np.mean(z)\n",
    "    return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
    "\n",
    "\n",
    "def weighted_mean_quadratic_weighted_kappa(solution, submission):\n",
    "    predicted_score = submission[submission.columns[-1]].copy()\n",
    "    predicted_score.name = \"predicted_score\"\n",
    "    if predicted_score.index[0] == 0:\n",
    "        predicted_score = predicted_score[:len(solution)]\n",
    "        predicted_score.index = solution.index\n",
    "    combined = solution.join(predicted_score, how=\"left\")\n",
    "    groups = combined.groupby(by=\"essay_set\")\n",
    "    kappas = [quadratic_weighted_kappa(group[1][\"essay_score\"], group[1][\"predicted_score\"]) for group in groups]\n",
    "    weights = [group[1][\"essay_weight\"].irow(0) for group in groups]\n",
    "    return mean_quadratic_weighted_kappa(kappas, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed78faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"./training_set_rel3.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    usecols=[\"essay_id\", \"essay_set\", \"essay\", \"domain1_score\", \"domain2_score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af931dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (2, 12),\n",
       " 2: (1, 6),\n",
       " 3: (0, 3),\n",
       " 4: (0, 3),\n",
       " 5: (0, 4),\n",
       " 6: (0, 4),\n",
       " 7: (2, 24),\n",
       " 8: (10, 60)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "essay_set_intervals = {}\n",
    "for essay_set in range(1, 9):\n",
    "    temp = df[df.essay_set == essay_set]\n",
    "    essay_set_intervals[essay_set] = temp.domain1_score.min(), temp.domain1_score.max()\n",
    "    \n",
    "essay_set_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5d6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(row):\n",
    "    target_lb = 0\n",
    "    target_ub = 3\n",
    "    essay_set = row[\"essay_set\"]\n",
    "    a, b = essay_set_intervals[essay_set]\n",
    "    return np.clip(\n",
    "        np.round(\n",
    "            target_lb + (target_ub - target_lb) / (b - a) * (row[\"domain1_score\"] - a)\n",
    "        ),\n",
    "        target_lb,\n",
    "        target_ub,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2af8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalized_score\"] = df.apply(normalize, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3875b716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_rating, max_rating = int(df.normalized_score.min()), int(df.normalized_score.max())\n",
    "min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8aa7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 7414, 1.0: 3351, 3.0: 1746, 0.0: 465})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(df.normalized_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b69e1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = pd.DataFrame({\n",
    "    \"prompt\": df.essay.tolist(),\n",
    "    \"completion\": df.normalized_score.tolist()})\n",
    "\n",
    "df_ft.to_json(f\"essay_set_full.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a7d1079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion\n",
       "0  Dear local newspaper, I think effects computer...         2.0\n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...         2.0\n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...         2.0\n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...         2.0\n",
       "4  Dear @LOCATION1, I know having computers has a...         2.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bbe97",
   "metadata": {},
   "source": [
    "# Generate data for Fine Tuning\n",
    "\n",
    "We run the following tool:\n",
    "\n",
    "`openai tools fine_tunes.prepare_data -f essay_set_full.jsonl -q`\n",
    "\n",
    "This will generate two data splits for the fine-tuning. One for training and other for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddc38e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-050YvpQyqalHUUFDGaMXGieC', created_at=1721597975, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-JihYzTh2GjJjoPtZZ0kQdsbr', result_files=[], seed=1736061865, status='validating_files', trained_tokens=None, training_file='file-S50elqSBviOxvvpFSfKtRnf7', validation_file='file-CyOBDSWb5QkysorcyzgF840B', estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "train_file = client.files.create(file=open(f\"essay_set_full_prepared_train.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "valid_file = client.files.create(file=open(f\"essay_set_full_prepared_valid.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(training_file=train_file.id, validation_file=valid_file.id, model=\"babbage-002\")\n",
    "print(fine_tuning_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4ba8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_results = client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n",
    "ft_model = fine_tune_results.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e13b03fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    556\n",
       "2    546\n",
       "4    528\n",
       "6    526\n",
       "1    524\n",
       "3    523\n",
       "7    459\n",
       "8    230\n",
       "Name: essay_set, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.sample(int(df.shape[0] * 0.3))\n",
    "test_df.essay_set.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "454821e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"There a lot of things to life and sometimes we do need as much help as we can get. Sometimes people will do anything to get help or go anywhere to find it. Because when people feel lost it's the most scraest thing to a person. So they turn to reading books, listening to music, watching movies, also looking and reading magazins. But although thats not the best way you can go there times when you need to listen to your soul the most.     Now there was a time when know one knew how to read or even was a loud to read. But now adays reading as taking over. If you can read you can do anything , you could be the one to run to whole world one day if you read things right.      Books and magazins there are is not a big different between the two. Books can take you mind off some where that you  have never seen before and places like the wild, @LOCATION2, @LOCATION1, @CAPS1's, and high up and trees. It teaches you @LOCATION1 thing  but not every thing it teaches is good. Books can lie about whats about to happen to the world. Now magazing show you what all the starts are doing and how there living and what there house looks like and there money their begin home. There one thing you have to understand you can't always get scraed and thing what you reading is right you have to read your mind it see what it says about what you just read.     When you hear your favtor song what do you or when you see your favtor movie? Do start dancing or do you cry when they break up, do you say I can sing like her or do you rein act the part in the movie. These things can help you or make you think about things you shouldn't do to people or even to yourself.     Music can make you think about what your life has been throw or miss the person that  has died because they listen to that one song so much. Music can talk you in to killing yourself drive you crazy, hurt your soul when hear what someone else has been throw. Its all about how you take the song when you first hear it and take the messages out of it.     Movies show history and show you want happens to people when they do the wrong things what will happen to them. There could be a ican in the movie your watching and could want to be like him/her. But not everyone you see you shouldn't want to be like them. You have to be yourself at the end of the day. Because you wake up looking at you everyday and love you everyday and take care of you everyday.     When it's all said and done you have to belive in yourself and  not listen to what everyone is trying you. Go with you soul. Yes listening to it or read or even watching ir but just remember flow your deams and do what you love. So thants what I thing about music,books,movie and magazing listen but don't listen at the same tim\",\n",
       " 1.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts, scores = test_df.essay.tolist(), test_df.normalized_score.tolist()\n",
    "texts[0], scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f34d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea7a424502f4674838faaa0b0526b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/3892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1b65419f0646a289f5c8ea8106e3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/3892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acefce69b8a4ef0988b9855e1cf76c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/3892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_scores(text: str, score: int):\n",
    "\n",
    "    prompt = text \n",
    "    # GPT4 fine-tuned model as a feature\n",
    "    prompt = prompt + '\\n\\n###\\n\\n'\n",
    "    res = client.completions.create(\n",
    "        model=ft_model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=2, temperature=0)\n",
    "\n",
    "    features = {}\n",
    "    gpt_score = int(re.sub(r\"[^0-9]\", \"\", res.choices[0].text)) % 10\n",
    "    features[\"gpt_score\"] = gpt_score\n",
    "    features[\"score\"] = score\n",
    "\n",
    "    return features\n",
    "\n",
    "# print(get_scores(texts[0], scores[0]))\n",
    "args = list(zip(texts, scores))\n",
    "train_result = pqdm(args, get_scores, n_jobs=8, argument_type=\"args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3347c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for res in train_result:\n",
    "    if type(res) != dict:\n",
    "        continue\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b31abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gpt_score  score\n",
       "0          1    1.0\n",
       "1          1    2.0\n",
       "2          1    1.0\n",
       "3          2    2.0\n",
       "4          1    1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_set = pd.DataFrame(results)\n",
    "essay_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576ed09",
   "metadata": {},
   "source": [
    "# GPT Performance GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4331dce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8320205990645835, 0.8391167192429022, 0.998422712933754)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = essay_set.gpt_score\n",
    "y_true = essay_set.score\n",
    "qwk = quadratic_weighted_kappa(y_true, y_pred, min_rating=min_rating, max_rating=max_rating)\n",
    "ea = np.sum(y_true == y_pred) / y_true.shape[0]\n",
    "aa = np.sum((y_true - y_pred) <= 1) / y_true.shape[0]\n",
    "qwk, ea, aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dc26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
